{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc132f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee04a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    221004\n",
      "1     30996\n",
      "Name: Risk_Flag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read in the training and testing datasets as pandas dataframes\n",
    "\n",
    "training = pd.read_csv('Training Data.csv')\n",
    "testing = pd.read_csv('Test Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc94f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.head()  \n",
    "# 'Risk_Flag' is the response variable, 1 indicating positive and 0 negative\n",
    "# The other columns are the explanatory variables: \n",
    "#     some are numerical and some are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e64d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = training['Risk_Flag'].value_counts() \n",
    "print(counts)  \n",
    "# By looking at the number of samples of each category, we can see that the dataset is imbalanced  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88062a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    30996\n",
      "0    30996\n",
      "Name: Risk_Flag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Here we undersample the data, randomly selecting the same number of samples where 'Risk_Flag == 0' \n",
    "# as there are samples where 'Risk_Flag == 1'\n",
    "\n",
    "balance_idx = torch.randperm(counts[0])[:counts[1.0]].tolist() \n",
    "default = training[training['Risk_Flag']==1.0]\n",
    "non_default = training[training['Risk_Flag']==0]\n",
    "non_default = non_default.iloc[balance_idx]\n",
    "training = pd.concat([default, non_default])\n",
    "\n",
    "# Verify that the training dataset is now balanced\n",
    "print(training['Risk_Flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432a325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodes all categorical features into numerical ones, for both training and testing datasets\n",
    "\n",
    "\n",
    "# Set all columns containing categorical features as type 'category'\n",
    "training[['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']] = training[['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']].astype('category')\n",
    "testing[['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']] = testing[['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']].astype('category')\n",
    "\n",
    "# Define those columns as separate variables\n",
    "cat_columns_train = training.select_dtypes(['category']).columns\n",
    "cat_columns_test = testing.select_dtypes(['category']).columns\n",
    "\n",
    "# Encodes those columns into integer representation by modifying the training and testing datasets\n",
    "training[cat_columns_train] = training[cat_columns_train].apply(lambda x: x.cat.codes)\n",
    "testing[cat_columns_test] = testing[cat_columns_test].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83cf0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = training.astype('float'), testing.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5cc6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training.drop(['Risk_Flag'], axis=1)\n",
    "y_train = training['Risk_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b2b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity\n",
    "\n",
    "X_train = X_train.drop(['Id','CITY','STATE','Experience'], axis=1)\n",
    "X_train, y_train = X_train.to_numpy().astype(np.float32), y_train.to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089a4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d045d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression\n",
    "from concrete.ml.sklearn import LogisticRegression as ConcreteLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "107b8f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = SklearnLogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9486c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34dee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_logreg = ConcreteLogisticRegression(n_bits={\"inputs\": 5, \"weights\": 2})\n",
    "q_logreg.fit(X_train, y_train)\n",
    "q_logreg.compile(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "902bde52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results = pd.read_csv('Sample Prediction Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e41bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test_results[['risk_flag']] \n",
    "\n",
    "combined_testset = pd.concat([testing, test_results], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf848b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Married/Single</th>\n",
       "      <th>House_Ownership</th>\n",
       "      <th>Car_Ownership</th>\n",
       "      <th>Profession</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CURRENT_JOB_YRS</th>\n",
       "      <th>CURRENT_HOUSE_YRS</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7393090.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1215004.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8901342.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1944421.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13429.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID     Income   Age  Experience  Married/Single  House_Ownership  \\\n",
       "0  1.0  7393090.0  59.0        19.0             1.0              2.0   \n",
       "1  2.0  1215004.0  25.0         5.0             1.0              2.0   \n",
       "2  3.0  8901342.0  50.0        12.0             1.0              2.0   \n",
       "3  4.0  1944421.0  49.0         9.0             0.0              2.0   \n",
       "4  5.0    13429.0  25.0        18.0             1.0              2.0   \n",
       "\n",
       "   Car_Ownership  Profession   CITY  STATE  CURRENT_JOB_YRS  \\\n",
       "0            0.0        26.0  181.0   28.0              4.0   \n",
       "1            0.0        24.0  131.0   14.0              5.0   \n",
       "2            0.0        30.0  290.0   14.0              9.0   \n",
       "3            1.0         1.0  171.0   14.0              3.0   \n",
       "4            1.0        12.0   39.0   28.0             13.0   \n",
       "\n",
       "   CURRENT_HOUSE_YRS  risk_flag  \n",
       "0               13.0          0  \n",
       "1               10.0          0  \n",
       "2               14.0          1  \n",
       "3               12.0          0  \n",
       "4               11.0          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb9e62ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simplify dataset by discarding less significant features\n",
    "# Analysis not included in this notebook\n",
    "# Analysis from: https://www.kaggle.com/code/paallakchopraa/loan-prediction\n",
    "combined_testset = combined_testset.drop(['ID','CITY','STATE','Experience'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556d028d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testset_counts = combined_testset['risk_flag'].value_counts()\n",
    "\n",
    "# undersampling for test set\n",
    "balance_idx_test = torch.randperm(testset_counts[0])[:testset_counts[1.0]].tolist()\n",
    "\n",
    "default_testing = combined_testset[combined_testset['risk_flag']==1.0]\n",
    "non_default_testing = combined_testset[combined_testset['risk_flag']==0]\n",
    "non_default_testing = non_default_testing.iloc[balance_idx_test]\n",
    "\n",
    "balanced_testing = pd.concat([default_testing, non_default_testing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3826b7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3593\n",
       "0    3593\n",
       "Name: risk_flag, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_testing['risk_flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acd009bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_testing_y = balanced_testing['risk_flag']\n",
    "balanced_testing_X = balanced_testing.drop(['risk_flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c08504bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_testing_X = balanced_testing_X.to_numpy()\n",
    "balanced_testing_y = balanced_testing_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87e90f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomises rows and convert to a numpy array\n",
    "balanced_test_idx = np.random.permutation(100)\n",
    "\n",
    "\n",
    "balanced_test_sample = balanced_testing_X[balanced_test_idx]\n",
    "\n",
    "balanced_test_results = balanced_testing_y[balanced_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07fb26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test small sample (We don't know how long it's gonna take to test all 7000 samples in the balanced test set)\n",
    "\n",
    "y_pred_test_clear = np.asarray(logreg.predict(balanced_test_sample))\n",
    "y_pred_test_q = q_logreg.predict(balanced_test_sample)\n",
    "y_pred_test_fhe = q_logreg.predict(balanced_test_sample, execute_in_fhe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_accuracy = np.sum(y_pred_test_clear == balanced_test_results) / len(y_test) * 100\n",
    "quantised_accuracy = (balanced_test_results == y_test).mean() * 100\n",
    "fhe_accuracy = (balanced_test_results == y_test).mean() * 100\n",
    "\n",
    "print(f\"Sklearn accuracy: {sklearn_accuracy:.4f}\")\n",
    "print(f\"Non Homomorphic Accuracy: {quantised_accuracy:.4f}\")\n",
    "print(f\"Homomorphic Accuracy: {fhe_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
